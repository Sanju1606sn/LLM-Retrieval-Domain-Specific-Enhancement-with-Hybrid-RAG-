
---

## 2ï¸âƒ£ LLM-RAG

```markdown
# ðŸ” LLM-RAG: Enhancing LLM Accuracy with Retrieval-Augmented Generation

This project explores **Retrieval-Augmented Generation (RAG)** to mitigate **LLM hallucinations** and improve accuracy for domain-specific queries.

## ðŸš€ Features
- Combines **retrievers** (BM25, Bi-Encoder, Cross-Encoder) with **LLMs (GPT, LLaMA)**.
- Implements **LoRA** and **QLoRA** fine-tuning for parameter-efficient adaptation.
- Cross-encoder retrievers demonstrated **best retrieval performance**.
- Achieved **higher exact-match accuracy** compared to standalone LLMs.

## ðŸ› ï¸ Tech Stack
- Python, Hugging Face Transformers  
- GPT, LLaMA models  
- BM25, Sentence-BERT, Cross-Encoder retrievers  
- LoRA / QLoRA fine-tuning  

## ðŸ“‚ Dataset
- Domain-specific QA dataset (course assignment: CS626, IIT Bombay).  

## ðŸ“Š Results
- **Cross-encoder > Bi-encoder > BM25** in retrieval accuracy.  
- **Fine-tuned LLM with RAG** outperformed both standalone fine-tuned LLMs and vanilla LLM+RAG.

